# 机器学习问题总结

## 统计学习方法方法特点概括总结

| 方法                 | 适用问题         | 模型特点                                           | 模型类型 | 学习策略                           | 学习的损失函数       | 学习算法                                   |
| -------------------- | ---------------- | -------------------------------------------------- | -------- | ---------------------------------- | -------------------- | ------------------------------------------ |
| 感知机               | 二分类           | 分离超平面                                         | 判别类型 | 极小化误分点到超平面的距离         | 误分点到超平面的距离 | 随机梯度下降                               |
| K 近邻               | 多类分类，回归   | 特征空间，样本点                                   | 判别模型 | -                                  | -                    | -                                          |
| 朴素贝叶斯法         | 多类分类         | 特征与类别的联合概率分布，属性条件独立性假设       | 生成模型 | 极大似然估计，极大后验概率估计     | 对数似然损失         | 概率计算公式，EM算法                       |
| 决策树               | 多类分类，回归   | 分类树，回归树                                     | 判别模型 | 正则化的极大似然估计               | 对数似然损失         | 特征选择，生成，剪枝                       |
| 逻辑回归与最大熵模型 | 二分类，多类分类 | 特征条件下类别的条件概率分布，对数线性模型         | 判别模型 | 极大似然估计，正则化的极大似然估计 | 对数损失函数         | 改进的迭代尺度算法，梯度下降算法，拟牛顿法 |
| 支持向量机           | 二分类           | 分离超平面，核技巧                                 | 判别模型 | 极小化正则化合页损失，软间隔最大化 | 合页损失             | 序列最小最优化算法SMO                      |
| 提升方法             | 二分类           | 弱分类器的线性组合                                 | 判别模型 | 极小化加法模型的指数损失           | 指数损失             | 前向分步加法算法                           |
| EM算法               | 概率模型参数估计 | 含隐变量概率模型                                   | -        | 极大似然估计，极大后验概率估计     | 对数似然损失         | 迭代算法                                   |
| 隐马尔科夫模型       | 标注             | 观测序列与状态序列的联合概率分布模型               | 生成模型 | 极大似然估计，极大后验概率估计     | 对数似然损失         | 概率计算公式，EM算法                       |
| 条件随机场           | 标注             | 状态序列条件下观测序列的条件概率分布，对数线性模型 | 判别模型 | 极大似然估计，正则化极大似然估计   | 对数似然损失函数     | 改进的迭代尺度算法，梯度下降算法，拟牛顿法 |

## 逻辑回归

逻辑回归虽然被称为是回归，但实际上是分类模型，常用于二分类，逻辑回归因其简单、可并行化、可解释性强深受工业届喜欢。**逻辑回归假设数据服从伯努利分布，通过极大化似然函数的方法，运用梯度下降来求解参数，来实现对数据进行二分类的问题。**

[逻辑回归面试题汇总(整理)](https://blog.csdn.net/weixin_42933718/article/details/88874376)<br>[逻辑回归的常见面试点总结](https://www.cnblogs.com/ModifyRong/p/7739955.html)<br>[逻辑回归](https://zhuanlan.zhihu.com/p/74874291)

### 逻辑回归的基本假设

逻辑回归的第一个基本假设是**假设数据服从伯努利分布**。在逻辑回归模型中，假设$h_\theta(x)$为样本为正的概率，$1-h_\theta(x)$为样为负的概率，则整个模型可以表示为$h_\theta(x;\theta) = p$。逻辑回归的第二个假设是假设样本为正的概率是$p = \frac{1}{1+e^{-\theta^Tx}}$。所以逻辑回归的最终形式是$h_\theta(x;\theta) =\frac{1}{1+e^{\theta^Tx}}$。

### 逻辑回归的损失函数

逻辑回归的损失函数的通过极大似然估计推导出来的，其形式是对数损失函数，所以从损失函数的角度来看，逻辑回归的损失函数就是对数损失函数。
$$
L_\theta\left(x\right )= \prod _{i=1}^{m}h_\theta(x^{i};\theta )^{y{i}}*(1-h_\theta(x^{i};\theta))^{1-y^{i}}
$$

### 逻辑回归为什么不用均方误差作为损失函数，而是使用极大似然函数求解参数？

1. 其一是因为如果你使用平方损失函数，会发现梯度更新的速度和sigmod函数本身的梯度是很相关的。sigmod函数在它在定义域内的梯度都不大于0.25。这样训练会非常的慢。
2. 其二是在使用 Sigmoid 函数作为正样本的概率时，同时将平方损失作为损失函数，这时所构造出来的损失函数是非凸的，不容易求解，容易得到其局部最优解。 
3. 而如果使用极大似然，其目标函数就是对数似然函数，该损失函数是关于未知参数的高阶连续可导的凸函数，便于求其全局最优解，而且对数损失函数的梯度更新和sigmod函数本身的梯度是无关的，这样更新的速度是可以自始至终都比较的稳定，其求解参数的速度是比较快的。对数损失函数的梯度更新公式
$$
\theta _j=\theta _j-\left ( y^{i} -h_\theta (x^{i};\theta ) \right )\ast x^{i}_j
$$

### 逻辑回归的求解方法

由于该极大似然函数无法直接求解，我们一般通过对该函数进行梯度下降来不断逼急最优解。常用的有随机梯度下降算法、批梯度下降算法和小批量梯度下降算法。
+ 简单来说 批梯度下降会获得全局最优解，缺点是在更新每个参数的时候需要遍历所有的数据，计算量会很大，并且会有很多的冗余计算，导致的结果是当数据量大的时候，每个参数的更新都会很慢。
+ 随机梯度下降是以高方差频繁更新，优点是使得sgd会跳到新的和潜在更好的局部最优解，缺点是使得收敛到局部最优解的过程更加的复杂。
+ 小批量梯度下降结合了随机梯度下降算法和批梯度下降算法的优点，每次更新的时候使用n个样本。减少了参数更新的次数，可以达到更加稳定收敛结果，一般在深度学习当中我们采用这种方法。

### 逻辑回归的目的

逻辑回归的目的是对数据进行二分类。逻辑回归作为一个回归(也就是y值是连续的)，如何应用到分类上去呢。y值确实是一个连续的变量。逻辑回归的做法是划定一个阈值，y值大于这个阈值的是一类，y值小于这个阈值的是另外一类。阈值具体如何调整根据实际情况选择。一般会选择0.5做为阈值来划分。

### 逻辑回归在训练的过程当中，如果有很多的特征高度相关或者说有一个特征重复了100遍，会造成怎样的影响？

先说结论，如果在损失函数最终收敛的情况下，其实就算有很多特征高度相关也不会影响分类器的效果。但是对特征本身来说的话，假设只有一个特征，在不考虑采样的情况下，你现在将它重复100遍。训练完以后，数据还是这么多，但是这个特征本身重复了100遍，实质上将原来的特征分成了100份，每一个特征都是原来特征权重值的百分之一。如果在随机采样的情况下，其实训练收敛完以后，还是可以认为这100个特征和原来那一个特征扮演的效果一样，只是可能中间很多特征的值正负相消了。

### 为什么我们还是会在训练的过程当中将高度相关的特征去掉？

1. 去掉高度相关的特征会让模型的可解释性更好;
2. 可以大大提高训练的速度，如果模型当中有很多特征高度相关的话，就算损失函数本身收敛了，但实际上参数是没有收敛的，这样会拉低训练速度。其次是特征多了，本身就会增大训练时间。

### 逻辑回归为什么要对特征进行离散化？

在工业界，很少直接将连续值作为特征喂给逻辑回归模型，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：
1. 稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展。
2. 离散化后的特征对异常数据有很强的鲁棒性。比如一个特征是年龄>30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰。
3. 逻辑回归属于广义线性模型，表达能力受限，单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型的表达能力，加大拟合。
4. 离散化后可以进行特征交叉(特征组合)，由$M+N$个变量变为$M\times N$个变量，进一步引入非线性，提升表达能力。
5. 特征离散化后，模型会更加稳定。如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。

总结：（1）计算简单；（2）简化模型；（3）增强模型的泛化能力，不受噪声的影响。

### 在逻辑回归模型中，为什么常常需要做特征交叉(特征组合)？

逻辑回归模型属于线性模型，线性模型不能很好的处理非线性特征，特征组合可以引入非线性特征，提升了模型的表达能力。另外，基本特征可以认为是全局建模，组合特征更加精细，是个性化建模，但对全局建模会对部分样本有偏，对每一个样本建模又会导致数据爆炸、过拟合，所以基本特征+特征组合兼顾了全局和个性化。

### 逻辑回归模型是线性模型吗？

1. 逻辑回归模型是一种广义线性模型，它虽然引入了sigmoid函数，是非线性模型，但是本质上还是一个线性回归模型。
2. 逻辑回归和线性回归首先都是广义的线性回归，在本质上没多大区别，区别在于逻辑回归多了个Sigmod函数，使样本映射到`[0,1]`之间的数值，从而来处理分类问题。另外逻辑回归是假设变量服从伯努利分布，线性回归假设变量服从高斯分布。逻辑回归输出的是离散型变量，用于分类，线性回归输出的是连续性的，用于预测。逻辑回归是用最大似然法去计算预测函数中的最优参数值，而线性回归是用最小二乘法去对自变量因变量关系进行拟合。

### 逻辑回归模型的输出值的实际意义是什么？

只有在满足： y服从伯努利分布；η和x之间存在线性关系时，输出值才是概率值。不满足的情况下，得到的输出值，只是置信度。假设 y 是一个服从伯努利分布的二值随机变量。该分布的参数为$\Phi = P(y=1)$。伯努利分布属于指数家族的一种情况，指数分布家族的形式为：$$P(x|\eta)=h(x)exp{\eta^TT(x)-A(\eta)}$$
它告诉我们：对于随机变量x，只要确定三个函数$h(x)$、$T(x)$、$A(\eta)$，就可以确定一类分布。 $\eta$用来确定该类分布的具体参数。从伯努利分布出发，可变形到与指数分布族一样的形式：
$$
P(y;\Phi) = \Phi^y(1-\Phi)^{1-y}\\=exp(log\Phi^y(1-\Phi)^{1-y}\\=exp(ylog\Phi+(1-y)(1-\Phi)\\=exp(log\frac{\Phi}{1-\Phi}y+log(1-\Phi))
$$
对应上面提到的三个函数：
$$
A(\eta)=-log(1-\Phi)=log(1+e^\eta)\\h(y) = 1\\T(y) = y
$$
$\eta​$和$\Phi​$之间的关系：
$$
\eta = log\frac{\Phi}{1-\Phi}\\\Phi = \frac{1}{1+e^{-\eta}}
$$
因此，伯努利分布可以改写为指数分布族的形式，而且，伯努利分布的参数$\Phi$与$\eta$之间，还满足sigmoid函数的关系。如果能找到x和$\eta$之间的关系，就找到了x和$\Phi$之间的关系。假设$\eta$和x之间存在线性的关系，即：$\eta = \theta x$。将$\Phi$作为预测值。$\Phi$既是伯努利分布的唯一参数，也是该分布的期望，也是逻辑回归的输出。至此，找到了我们要用的模型的样子，也就是逻辑回归。

如果你的情况满足上面所说的两个假设，那么你训练模型的过程，就确实是在对概率进行建模。但是这两个假设并不是那么容易满足的。所以，很多情况下，我们得出的逻辑回归输出值，无法当作真实的概率，只能作为置信度来使用。

### 逻辑回归模型的优缺点(偏向工业界)

#### 优点

1. 形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响，某个特征的权重值比较高，那么这个特征最后对结果的影响会比较大。
2. 模型效果不错。在工程上是可以接受的，如果特征工程做的好，效果不会太差，并且特征工程可以大家并行开发，大大加快开发的速度。
3. 训练速度较快。分类的时候，计算量仅仅只和特征的数目相关。并且逻辑回归的分布式优化sgd发展比较成熟，训练的速度可以通过堆机器进一步提高，这样我们可以在短时间内迭代好几个版本的模型。
4. 资源占用小,尤其是内存。因为只需要存储各个维度的特征值。
5. 方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数(置信度)。

#### 缺点

1. 准确率并不是很高。因为形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布。
2. 很难处理数据不平衡的问题。
3. 处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据，或者进一步说，处理二分类的问题。
4. 逻辑回归本身无法筛选特征。有时候，我们会用`gbdt`来筛选特征，然后再上逻辑回归。

### 正则化

正则化是一个通用的算法和思想，所有会产生过拟合现象的算法都可以使用正则化来避免过拟合。在经验风险最小化的基础上（也就是训练误差最小化），尽可能采用简单的模型，可以有效提高泛化预测精度。如果模型过于复杂，变量值稍微有点变动，就会引起预测精度问题。正则化之所以有效，就是因为其降低了特征的权重，使得模型更为简单。正则化一般会采用 $L_1$ 范式或者 $L_2$ 范式。

#### $L_1$正则化 (Lasso回归)

相当于为模型添加了一个先验知识，即w服从零均值拉普拉斯分布$f(w|\mu,b)=\frac{1}{2b}exp(-\frac{|w-\mu|}{b})$。由于引入了先验，似然函数变为。
等价于原始损失函数的后面加上了 $L_1$ 正则，因此 $L_1$ 正则的本质其实是为模型增加了“**模型参数服从零均值拉普拉斯分布**”这一先验知识。

#### $L_2$正则化 (岭回归)

相当于为模型添加了一个先验知识：即 w 服从零均值正态分布。
由于引入了先验知识，所以似然函数这样写：
取 ln 再取负，得到目标函数：
等价于原始的损失函数后面加上了 $L_2$正则，因此 $L_2$ 正则的本质其实是为模型增加了**模型参数服从零均值正态分布**这一先验知识。

#### $L_1$和$L_2$正则化的区别

$L_1$ 正则化增加了所有权重 w 参数的绝对值之和逼迫更多 w 为零，也就是变稀疏。我们对稀疏规则趋之若鹜的一个关键原因在于它能实现特征的自动选择。一般来说，大部分特征 $x_i$ 都是和最终的输出 $y_i$ 没有关系或者不提供任何信息的。在最小化目标函数的时候考虑 $x_i$ 这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的特征权重反而会被考虑，从而干扰了对正确 $y_i$ 的预测。$L_1$ 正则化的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些无用的特征，也就是把这些特征对应的权重置为0。

$L_2$正则化中增加所有权重 w 参数的平方之和，逼迫所有 w 尽可能趋向零但不为零（$L_2$的导数趋于零）。因为在未加入 $L_2$正则化发生过拟合时，拟合函数需要顾忌每一个点，最终形成的拟合函数波动很大，在某些很小的区间里，函数值的变化很剧烈，也就是某些 w 值非常大。为此，$L_2$正则化的加入就惩罚了权重变大的趋势。

$L_1$正则化指权值向量中各个元素的绝对值之和，$L_2$正则化是指权值向量中各个元素的平方和再求平方根。$L_1$正则会产生稀疏解，$L_2$正则会产生比较小的解。以二维为例，$L_1$正则化项和误差项的交点常出现在坐标轴上，是个菱形，$w_1$或$w_2$为0，即权值向量中有零值元素，而$L_2$正则化项与误差项的交点常出现在某个象限中，是个圆，$w_1$和$w_2$均非0。

### 工程上，怎么实现逻辑回归的并行化？有哪些并行化工具？

逻辑回归的并行化最主要的就是**对目标函数梯度计算的并行化**。目标函数的梯度向量计算中只需要进行向量间的点乘和相加，可以很容易将每个迭代过程拆分成相互独立的计算步骤，由不同的节点进行独立计算，然后归并计算结果。算法的并行化有两种：**无损并行化和有损并行化**。
基于Batch的算法(Batch-GD, LBFGS, OWLQN)都是可以进行无损的并行化的。而基于SGD的算法（Ad Predictor， FTRL－Proximal）都只能进行有损的并行化。

1. 无损的并行化：算法天然可以并行，并行只是提高了计算的速度和解决问题的规模，但和正常执行的结果是一样的。
2. 有损的并行化：算法本身不是天然并行的，需要对算法做一些近似来实现并行化，这样并行化之后的双方和正常执行的结果并不一致，但是相似的。

并行化的工具有**MPI**和**OpenMP**。

### 逻辑回归与其他模型的比较

#### 与线性回归模型

逻辑回归是在线性回归的基础上加了一个 sigmoid 函数（非线形）映射，使得逻辑回归称为了一个优秀的分类算法。本质上来说，两者都属于广义线性模型，但他们两个要解决的问题不一样，逻辑回归解决的是分类问题，输出的是离散值，线性回归解决的是回归问题，输出的连续值。

sigmoid的作用：
+ 线性回归是在实数域范围内进行预测，而分类范围则需要在 [0,1]，逻辑回归减少了预测范围；
+ 线性回归在实数域上敏感度一致，而逻辑回归在 0 附近敏感，在远离 0 点位置不敏感，这个的好处就是模型更加关注分类边界，可以增加模型的鲁棒性。

#### 与最大熵模型

逻辑回归和最大熵模型本质上没有区别，最大熵在解决二分类问题时就是逻辑回归，在解决多分类问题时就是多项逻辑回归。

#### 与SVM模型

相同点：<br>
1. 都是分类算法，本质上都是寻找划分超平面
2. 都是监督学习算法
3. 都是判别式模型
4. 都可以通过核技巧的方法对非线性情况进行分类
5. 都能减少离群点的影响

不同点：<br>
1. 损失函数不同，LR是对数损失函数，SVM是合页损失函数。
2. LR对异常值敏感，SVM对异常值不敏感。解释：支持向量机只考虑局部的边界线附近的点，而逻辑回归考虑全局。LR模型找到的那个超平面，是尽量让所有点都远离他，而SVM寻找的那个超平面，是只让最靠近中间分割线的那些点尽量远离，即只用到那些支持向量的样本。 支持向量机改变非支持向量样本并不会引起决策面的变化。逻辑回归中改变任何样本都会引起决策面的变化。
3. 对非线性问题的处理方式不同。解释：LR主要通过特征构造，特征组合(特征交叉)、特征离散化来处理非线性问题。SVM通常采用核函数来高效处理非线性问题。
4. 理论基础不一样。LR基于统计，而SVM基于严格的数学推导。
5. 输出不同。LR可以对每个样本点给出类别判断的概率值(或置信度)，SVM无法做到。
6. 计算复杂度不同。对于海量数据，SVM的效率较低，LR的效率比较高。解释：当样本较少，特征维数较低时，SVM和LR的运行时间均比较短，SVM较短一些。准确率的话，LR明显比SVM要高。当样本稍微增加些时，SVM运行时间开始增长，但是准确率赶超了LR。SVM时间虽长，但在可接受范围内。当数据量增长到20000时，特征维数增长到200时，SVM的运行时间剧烈增加，远远超过了LR的运行时间。但是准确率却和LR相差无几。(这其中主要原因是大量非支持向量参与计算，造成SVM的二次规划问题)
7. 防止过拟合的能力不同。解释：SVM模型中内含了L2正则，可有效防止过拟合。LR要自己添加正则项。
8. 对数据要求不同。解释：**SVM依赖于数据表达出的距离测度，所以需要对数据进行标准化处理**，而LR不需要。
9. SVM会用核函数而LR一般不用核函数。
10. SVM自带结构风险最小化，LR则是经验风险最小化。

## 支持向量机

### SVM的原理，

支持向量机是一种二分类模型，它的**基本模型是在特征空间中寻找间隔最大化的分离超平面的线性分类器**。学习策略是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。
+ 当训练数据线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机。
+ 当训练数据近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机。
+ 当训练数据线性不可分时，通过使用核技巧以及软间隔最大化，学习一个非线性支持向量机。

### SVM为什么采用间隔最大化？

1. 当训练数据线性可分时，就会存在无数个分离超平面可以将训练数据正确分开 (感知机模型)。
2. 线性可分支持向量机利用间隔最大化求得最优分离超平面，这时，解释唯一的。
3. 另一方面，通过最大化间隔求得的分离超平面所产生的的分类结果是最鲁棒的，对未知实例的泛化能力最强。

可以借此机会阐述一下几何间隔以及函数间隔的关系。

### SVM推导中的函数间隔和几何间隔

#### 函数间隔

#### 几何间隔

### SVM的推导？

函数间隔 -> 几何间隔 -> 几何间隔最大化 -> 函数间隔最大化 -> 拉格朗日函数 -> 求解对偶问题 -> SMO算法
手推！！！

线性可分 - 硬间隔最大化 - 线性可分支持向量机
线性近似可分 - 软间隔最大化 - 线性可分支持向量机
线性不可分 - 核函数 - 非线性支持向量机

### SVM为什么转换为对偶问题求解？

+ 转换对偶问题求解减少算法复杂度，使得算法更高效，从求解w,b转换成求解$\alpha$；
+ 不等式约束是优化问题中的难点，求解对偶问题可以将支持向量机原问题中的不等式约束转换成等式约束；
+ 支持向量机在解决非线性可分问题时，需要将数据映射到高维空间，但映射函数的具体形式不容易确定，而转换成对偶问题时，可以使用核函数来解决这个问题。

### SVM 为什么要引入核函数？

1. 当样本在原始空间线性不可分时，可将样本从原始空间映射到一个更高维的特征空间，使得样本在高维特征空间内线性可分。
2. 引入这样的映射后，在所要求解的对偶问题的求解中，无需求解真正的映射函数，而只需要知道其核函数。
3. 核函数的引入避免了“维数灾难”，大大减小了计算量。
4. 无需知道非线性变换函数$\Phi$的形式和参数，只需要给定具体的核函数即可，这样使得求解的难度大大降低。
5. 核函数的形式和参数变换会隐式的改变从输入空间到特征空间的映射，进而对特征空间的性质产生影响，最终改变各种核函数方法的性能。

### SVM核函数的选择依据，以及各种核函数的区别？

一般选择线性核和高斯核，也就是线性核和RBF核。**需要注意的是需要对数据归一化处理**。
1. 线性核：主要用于线性可分的情形，参数少，速度快，对于一般数据，分类效果已经很理想了。
2. RBF核：主要用于线性不可分的情形。参数多，分类结果非常依赖于参数。可通过交叉验证来寻找合适的参数，不过这个过程比较耗时。如果特征的数量很大，跟样本数量差不多，这时候选用线性核的SVM；如果特征的数量比较小，样本数量一般，不算大也不算小，选用高斯核的SVM。
3. 对于某些参数，RBF和sigmoid具有相似的性能。
4. 其他核函数：cosin核，Chi-squared核。

### SVM如何处理多分类问题？

一般有两种做法：一种是直接法，直接在目标函数上修改，将多个分类面的参数求解合并到一个最优化问题里面，看似简单但是计算量却非常的大。另外一种做法是间接法：对训练器进行组合。其中比较典型的有一对一，和一对多。

+ **一对多**：就是对每个类都训练出一个分类器，由于svm是二分类，因此将目标类作为一类，其余类作为另外一类。这样针对k个类可以训练出k个分类器，当有一个新的样本来的时候，用这k个分类器来测试，哪个分类器的概率高，那么这个样本就属于哪一类。这种方法效果不太好，bias比较高。
+ **一对一**：针对任意两个类训练出一个分类器，如果有k类，一共训练出C(2,k) 个分类器，这样当有一个新的样本要来的时候，用这C(2,k)个分类器来测试，每当被判定属于某一类的时候，该类就加一，最后票数最多的类别被认定为该样本的类。

### SVM的主要优势、特点

1. 泛化性能比较好，不容易过拟合(合页损失函数+自带正则)。
2. 可以在较少的数据下取得较好的性能(支持向量)。
3. 存在全局最优解 (严格数学推导, 凸二次规划问题)。
4. 存在高效实现的训练算法(SMO算法)。
5. 可以使用核技巧处理非线性问题。
6. SVM的最终决策函数只由少数的支持向量所确定，计算的复杂性取决于支持向量的数目，而不是样本空间的维数，这在某种意义上避免了“维数灾难”。

### SVM的主要缺点

1. SVM算法对大规模训练样本难以实施，速度慢。
2. 用SVM解决多分类问题存在困难。
3. 对缺失数据(缺失的特征数据)敏感，对参数和核函数的选择敏感。

### 为什么SVM对缺失数据敏感？

1. 这里说的缺失数据是指缺失某些特征数据、向量数据不完整。
2. 因为SVM没有处理缺失值的策略，而SVM希望样本在特征空间线性可分，所以特征空间的好坏对SVM的性能很重要，缺失特征数据将影响训练结果的好坏。

### SMO算法的求解对偶问题流程？

SMO算法是一种启发式算法，其基本思路是：如果所有变量都满足此优化问题的KKT条件，那么这个最优化问题的解就得到了(因为KKT条件是该最优化问题的充分必要条件)。否则，选择两个变量，固定其他变量，针对这两个变量构建一个二次规划问题，这时构建的这个子问题可以通过解析方法求解，大大提高了算法的计算速度，子问题有两个变量，一个是违反KKT最严重的那一个，另一个是由约束条件自动确定。SMO包括两部分：求解两个变量的二次规划的解析方法和选择变量的启发式方法。

变量的选择方法：

+ 第一个变量的选择：SMO称第一个变量选择过程为外层循环，选取最违反KKT条件的样本点，在检验过程中，先遍历所有满足条件的$0\le \alpha_i \le C$的样本点(即在间隔边界上的支持向量点)，检验是否满足KKT条件，如果都满足，那么遍历整个训练集。检验他们是否满足KKT条件。
+ 第二个变量的选择：称为为内层循环，选择标准为希望能使$\alpha_2$有足够大的变化，一种简单的做法是选择$\alpha_2$,使其对应的$|E_1-E_2|$最大。在特殊情况下，若以上方法找不到$\alpha_2$，则遍历间隔边界上的支持向量点，依次将其对应的变量作为$\alpha_2$试用，直到目标函数有足够的的下降。若找不到合适的$\alpha_2$,那么遍历整个训练集，若仍找不到，则放弃$\alpha_1$,重新找$\alpha_1$。

SMO算法不断地将原二次规划问题分解为只有两个变量的二次规划子问题，并对子问题进行解析求解，知道所有的变量满足KKT条件为止，因为子问题有解析解，所以每次计算子问题都很快，虽然计算子问题的次数很多，但总体还是高效的。

### SVM和逻辑回归的异同

相同点：<br>
1. LR和SVM都是分类算法
2. LR和SVM都是监督学习算法
3. LR和SVM都是判别式模型
4. 如果不考虑核函数，LR和SVM都是线性分类算法，即他们的分类决策面是线性的。(注意：LR也可以核化，但是计算量太大，一般不这么做)

不同点：<br>
1. LR采用-log损失(对数损失函数)，SVM采用合页损失函数(hinge)
2. LR对异常值敏感，SVM对异常值不敏感
3. 计算复杂度不同，对于海量数据，SVM效率较低，LR效率较高
4. 对于非线性问题的处理方式不同
5. SVM的损失自带正则
6. SVM自带结构风险最小化，LR则是经验风险最小化。
7. SVM一般会使用核函数，LR一般不使用核函数。

## 决策树

### 什么是决策树？简述决策树的原理

决策树是一种基本的分类回归方法，可以从三个层面理解它：
1. 决策树模型是一种描述对实例进行分类和回归的树型结构，由结点和有向边组成，内部结点表示一个特征或属性，叶结点表示一个类。
2. 可以将决策树看成是一个`if-then`规则的集合，从根节点到叶结点的每一条路径构建一条规则，叶结点的类对应着规则的结论。这个规则集合互斥并完备。
3. 还可以将决策树表示为给定条件下类的条件概率分布，这个概率分布是定义在特征空间上的一个划分上。将特征空间划分为互不相交的单元或区域，并在每个单元定义一个类的概率分布就构成一个条件概率分布。决策树的一条路径对应于划分中的一个单元，决策树所表示的条件概率分布由各个单元给定条件下的类的条件概率分布组成。决策树分类预测时将该节点的实例强行分到条件概率大的那一类去。

### 简述决策树的构建过程和学习过程

决策树学习的算法通常是一个递归地选择最优特征并根据该特征对训练数据集进行分割，使得对各个子数据集有一个最好的分类的过程。开始，构建根节点，将所有训练数据都放在根节点，选择一个最优特征，按照这一特征将训练数据分割成子集，使得各个子集在当前条件下有一个最好的分类，如果这些子集已经基本被正确分类，那么构建叶子结点，并将这些子集分到所对应的叶子结点中去，如果还有子集不能被正确分类，则对这些子集选择新的最优特征，继续对其进行分割，构建结点，递归这一过程，直到所有子集都基本被正确分类，或没有合适的特征可供选择时，则停止，最后，每个子集都有了明确的类别标签。

决策树学习的本质上是从训练数据集中归纳出一组分类规则，它是一个与训练数据有较小矛盾，同时在具有很好的泛化能力的决策树。从另一个角度来看，决策树学习是由训练数据集估计条件概率模型。决策树学习的损失函数通常是正则化的极大似然函数，决策树学习的策略是以损失函数为目标函数的最小化。

如果特征数量很多时，可以在决策树学习的开始时，对特征进行选择，只留下对训练数有足够分类能力的特征。

### 决策树生成的迭代终止条件

+ 子节点中的样本属于同一类
+ 该子节点没有样本了
+ 特征已经用完了

### 如何选择最优特征？

选取对训练数据具有分类能力的特征。常用的评价特征的准则有：信息增益，信息增益率，基尼指数等。以信息增益为例，它表示得知特征X的信息而使得类Y的信息不确定性减少的程度。信息增益越大，说明特征X减少Y的不确定的程度越大。

### 谈谈对信息增益和信息增益率的理解

要理解信息增益，首先要理解熵这个概念。从概率统计的角度看，熵是对随机变量不确定性的度量，也可以说是对随机变量的概率分布的一个衡量。**熵越大，随机变量的不确定性就越大。对同一个随机变量，当他的概率分布为均匀分布时，不确定性最大，熵也最大。对有相同概率分布的不同的随机变量，取值越多的随机变量熵越大**。其次，要理解条件熵的概念。正如熵是对随机变量不确定性的度量一样，条件熵是指，有相关的两个随机变量X和Y，在已知随机变量X的条件下，随机变量Y的不确定性。当熵和条件熵中概率由数据估计（特别是极大似然估计）得到时，所对应的熵与条件熵分别为经验熵与经验条件熵。<br>
**信息增益**，也叫互信息，就是指集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D∣A)之差。ID3算法在每一次对决策树进行分叉选取最优特征时，会选取信息增益最高的特征来作为分裂特征。**信息增益准则对那些特征的取值比较多的特征有所偏好**，也就是说，采用信息增益作为判定方法，会倾向于去选择特征取值比较多的特征作为最优特征，为了减少这种偏好带来的不利影响，信息增益率对这一问题进行了校正。
$$
g_R(D,A) = \frac{g(D,A)}{H(D)}
$$

### 决策树出现过拟合的原因及其解决办法？

对训练数据预测效果很好，但是测试数据预测效果较差的现象称为过拟合。

原因：<br>
+ 在决策树的构建过程中，对决策树的生长没有进行合理的限制(剪枝)；
+ 样本中有一些噪声数据，没有对噪声数据进行有效的剔除；

解决办法：<br>
+ 选择合理的参数进行剪枝，可以分为预剪枝和后剪枝，一般采用的后剪枝的方法。
+ 有效地抽样，用相对能够反映业务逻辑的训练集去产生决策树

### 为什么决策树需要进行剪枝？如何进行决策树的剪枝？

决策树生成算法迭代地产生决策树，直到不能继续下去为止，这样产生的决策树往往对训练数据的分类很准确，但对未知的测试数据的分类却没有那么准确，即会出现过拟合的现象，过拟合的原因在于学习时过多的考虑如何提高对训练数据的正确分类，从而构建出了过于复杂的决策树。决策树的剪枝就是为了解决过拟合的现象。

决策树的剪枝通常通过极小化决策树整体的损失函数来实现。

$$
C_{\alpha}(T) = \sum_{t=1}^{|T|}N_tH_t(T)+\alpha|T|
$$

其中$H_t(T)$为经验熵，$N_t$为样本点数，$|T|$为树T的叶结点个数。

$$
H_t(T) = -\sum_k \frac{N_{tk}}{N_t}log\frac{N_{tk}}{N_t}\\C(T) = \sum_{t=1}^{|T|}N_tH_t(T) = -\sum_{t=1}^{|T|} \sum_{k=1}^K N_{tk}log\frac{N_{tk}}{N_t}\\C_{\alpha} = C(T)+\alpha|T|
$$

记第一项为$C(T)$，表示模型对训练数据的预测误差，即模型与训练数据的拟合程度。$|T|$表示模型的复杂度。$\alpha$控制两者之间的影响。

剪枝，就是当$\alpha$确定时，选择损失函数最小的模型，即损失函数最小的子树，当$\alpha$确定时，子树越大，拟合的越好，但模型的复杂度越高，反之，子树越小，模型复杂度低但拟合不好。可以看出决策树的生成只考虑了通过提高信息增益对训练数据进行更好的拟合，而决策树剪枝通过优化损失函数还考虑了减小模型的复杂度，决策树的生成学习局部的模型，而决策树的剪枝学习整体的模型。**决策树的损失函数极小化等价于正则化的极大似然估计，即利用损失函数最小原则进行剪枝就是用正则化的极大似然估计进行模型选择**。

### C4.5对ID3做了哪些改进？

#### ID3的不足
1. ID3没有考虑连续特征。
2. ID3采用信息增益大的特征优先建立决策树的节点，对那些特征的取值比较多的特征有所偏好。
3. ID3算法对于缺失值的情况没有做考虑。
4. 没有考虑过拟合的问题。

#### C4.5 对 ID3 的改进
1. 对于ID3不能处理连续特征，C4.5的思路是将连续的特征离散化。
2. 针对第二个不足，C4.5采用信息增益率来进行校正。
3. 对于ID3的第3个缺失值处理的问题，主要需要解决的是两个问题，一是在样本某些特征缺失的情况下选择划分的属性，二是选定了划分属性，对于在该属性上缺失特征的样本的处理。**对于第一个子问题**，对于某一个有缺失特征值的特征A。C4.5的思路是将数据分成两部分，对每个样本设置一个权重（初始可以都为1），然后划分数据，一部分是有特征值A的数据D1，另一部分是没有特征A的数据D2。然后对于没有缺失特征A的数据集D1来和对应的A特征的各个特征值一起计算加权重后的信息增益比，最后乘上一个系数，这个系数是无特征A缺失的样本加权后所占加权总样本的比例。**对于第二个子问题**，可以将缺失特征的样本同时划分入所有的子节点，不过将该样本的权重按各个子节点样本的数量比例来分配。比如缺失特征A的样本a之前权重1，特征A有3个特征值A1,A2,A3。3个特征值对应的无缺失A特征的样本个数为2,3,4.a同时划分入A1,A2,A3。对应权重调节为2/9,3/9, 4/9。
4. 对于ID3的第4个问题，C4.5引入了正则化系数进行剪枝。

### 决策树如何处理连续数值型属性(C4.5中)？

因为连续属性的可取值数目不再有限，因此不能像前面处理离散属性枚举离散属性取值来对结点进行划分。因此**需要连续属性离散化，常用的离散化策略是二分法。** 参考周志华的机器学习(西瓜书)

### 决策树是如何处理缺失值的（C4.5中）？

主要需要解决的是两个问题，**一是在样本某些特征缺失的情况下选择划分的属性，二是选定了划分属性，对于在该属性上缺失特征的样本的处理**。**对于第一个子问题**，对于某一个有缺失特征值的特征A。C4.5的思路是将数据分成两部分，对每个样本设置一个权重（初始可以都为1），然后划分数据，一部分是有特征值A的数据D1，另一部分是没有特征A的数据D2。然后对于没有缺失特征A的数据集D1来和对应的A特征的各个特征值一起计算加权重后的信息增益比，最后乘上一个系数，这个系数是无特征A缺失的样本加权后所占加权总样本的比例。**对于第二个子问题**，可以将缺失特征的样本同时划分入所有的子节点，不过将该样本的权重按各个子节点样本的数量比例来分配。比如缺失特征A的样本a之前权重1，特征A有3个特征值A1,A2,A3。3个特征值对应的无缺失A特征的样本个数为2,3,4.a同时划分入A1,A2,A3。对应权重调节为2/9,3/9, 4/9。

### 简述一下分类回归树(CART)

CART假设决策树是二叉树，内部结点特征的取值为“是”和“否”，左分支是取值为“是”的分支，右分支时取值为“否”的分支，这样的决策树等价于递归地二分每个特征，将输入空间划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。

**对于回归树用平方误差最小化准则，对于分类树用基尼指数最小化准则**。

### CART如何生成回归树？

懒的敲了，我之前手写过，直接上图。。

### CART对离散特征取值数目大于等于3的特征如何处理？

分类树的生成中，根据特征A是否取某一可能的值a被分割为D1和D2两部分。

### 决策树需要进行归一化处理吗？

**不需要**。概率模型（树形模型）不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率，如决策树、RF。而像Adaboost、SVM、LR、Knn、KMeans之类的最优化问题就需要归一化。

这儿可能引出为什么需要进行归一化。

### 决策树在选择特征进行分类时一个特征被选择过后，之后还会选择到这个特征吗？

在ID3和C4.5中，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性。参考周志华机器学习85页。<br>
在CART中，一个特征被选择之后，这个特征还有可能被选择。

### 和其他模型比，决策树有哪些优点和缺点？

优点：<br>
1. 决策树算法易于理解，机理解释起来简单。
2. 决策树算法可以用于小数据集。
3. 决策树算法的时间复杂度较小，为用于训练决策树的数据点的对数。
4. 能够处理多输出的问题。 
5. 对缺失值不敏感。
6. 可以同时处理类别数据和数值数据。
7. 可以处理不相关特征数据。
8. 效率高，决策树只需要一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。

缺点：<br>
1. 对连续性的字段比较难预测。
2. 容易出现过拟合。
3. 当类别太多时，错误可能就会增加的比较快
4. 在处理特征关联性比较强的数据时表现得不是太好。

## 提升方法(集成学习)

### RF、XGBoost和GBDT的原理？RF和XGBoost/GBDT的区别？XGBoost和GBDT的区别?

RF，GBDT和XGBoost都属于集成学习(Ensemble Learning)。集成学习的目的是通过结合多个基学习器的预测结果来改善单个学习器的泛化能力和鲁棒性。根据个体学习器的生成方式，可将目前的集成学习方法分为两大类：(1)个体学习器之间存在强依赖关系，必须串行生成的序列化方法(Boosting系列方法)；(2)个体学习器之间不存在强依赖关系，可同时生成的并行化方法(bagging,随机森林 RF)。

### RF(随机森林)原理

随机森林是Bagging(简单理解为：放回抽样(自主采样法)，多数表决(分类)或简单平均(回归)，其基学习器之间属于并列生成，不存在强依赖关系)的扩展变体，它以决策树为基学习器，构建Bagging集成的基础上进一步在决策树的训练过程中引入了**随机属性选择**。因此可包括四个部分：随机选择样本(自主采样法)、随机属性选择、构建决策树、随机森林投票(平均)。

随机选择样本与Bagging相同；随机属性选择是在构建树的过程中，先从样本集的特征集合中随机选择部分特征(属性)，然后再从这个子集中选择最优属性用于划分，这种随机性导致随机森林的偏差会有稍微的增加(相比于单棵非随机树)，但由于随机森林的“平均”性质，会使得它的方差减小，而方差减小补偿了偏差的增大，因此总体会得到更好的模型。在构建决策树的时候，RF的每棵决策树都最大可能的进行生长而不进行剪枝，在对预测输出进行结合时，RF对于分类任务采用投票，回归任务采样平均法。

**RF的重要特性是不对其进行交叉验证或者使用一个独立的测试集获得无偏估计，它可以在内部进行评估，也就是说在生成的过程中可以对误差进行无偏估计，由于每一个基学习器只使用了训练集中约63.2%的样本，剩余的样本可用作验证集来对其泛化性能进行“包外估计”。**

RF和Bagging比较：RF其实性能较差，特别是当只有一个基学习器的时候，随着学习器数目的增多，随机森林通常会收敛于更低的泛化误差。随机森林的训练效率也高于Bagging，因为在单个决策树的构建过程中Bagging使用的是“确定”决策树，即在选择特征划分结点时需要考虑所有的属性，而随机森林则是随机选取部分属性来构建决策树。

优点：

+ 简单，易实现，计算开销小，容易理解和解释，树可以被可视化；
+ 能够处理很高维的数据，并且不用特征选择，而且训练完成后，给出特征的重要性；
+ 隐含地创建了多个联合特征，并能够解决非线性问题；
+ 自带out-of-bag(包外估计)错误评估能力
+ 容易做成并行化方法

缺点：

+ 不适合小样本，只适合大样本；
+ 大多数情况下，RF模型的精度略低于GBDT模型的精度；
+ 适合决策边界是矩形的，不适合对角线型。

### GBDT(梯度提升树)

先介绍一下Boosting，它是也是一种集成方法，但与Bagging不同的是，不同的分类器是通过串行训练而获得的，每个分类器都根据已训练的分类器的性能来进行训练。Boosting是通过关注被已有分类器错分的那些数据来获得新的分类器。Boosting分类的结果是基于所有分类器的加权求和的结果，每个权重代表对应的分类器在上一轮迭代中的成功度，而Bagging是的分类器的权重是一样的。

GBDT与传统的Boosting区别较大，**它的每一次计算都是为了减少上一次的残差，而为了消除残差，我们在残差减小的梯度方向上建立模型**，所以说，在GradientBoost(GB)中，**之后每个基学习器的建立都是为了拟合与之前模型的残差**。**在GB算法中，关键就是利用损失函数的负梯度方向在当前模型的值作为残差的近似值，进而拟合一棵CART树**。GBDT会累加所有树的结果，而这种累加是无法通过分类完成的，因此GBDT树都是CART回归树，而不是分类树(尽管GBDT调整后也可以用于分类但不代表GBDT的树是分类树)。

优缺点：GBDT的性能在RF的基础上又有进一步的提升；它能灵活处理各种类型的数据；在相对较少的调参时间下，预测的准确度较高。由于其实Boosting，基学习器之间存在串行关系，难以并行训练数据。

### XGBoost原理

XGBoost是GB算法的高效实现，其在GBDT的基础上进一步提升，能够自动地应用CPU的多线程进行并行计算，同时在算法精度上也进行了精度的提高。

+ XGBoost中的基学习器除了可以是CART也可以是线性分类器。
+ **传统的GBDT在优化的时候只用到一阶导数信息，XGBoost则对代价函数进行了二阶泰勒展开，得到一阶和二阶导数**；
+ XGBoost在**代价函数中加入了正则项**，用于控制模型的复杂度，降低了模型的方差，防止过拟合；
+ 对缺失值的处理。对特征值有缺失的样本，XGBoost可以自动学习出它的分裂方向；
+ XGBoost支持并行；
+ 列抽样。XGBoost借鉴了随机森林的做法，支持列抽样，不仅防止过拟合，还能减少计算量。

### GBDT与RF的相同点

+ 都是由多棵树组成；
+ 最终的结果都是由多棵树一起决定。

### GBDT与RF的不同点

+ 组成随机森林的树可以是分类树，也可以是回归树，而GBDT只能是回归树；
+ 组成随机森林的树可以并行生成，而GBDT只能串行生成；
+ 对于最终的输出结果而言，随机森林采用多数投票等，而GBDT则是将所有结果累加起来，或者加权累加起来；
+ 随机森林对异常值不敏感，GBDT对异常值非常敏感；
+ 随机森林对训练集一视同仁，GBDT是基于权值的弱分类器集成；
+ 随机森林是通过减少模型方差提高性能，GBDT是通过减少偏差提高性能。

## 机器学习过程中的问题

### 梯度消失和梯度爆炸的产生的原理以及常用解决方法是什么？

梯度爆炸现象：损失出现NAN，一般出现在深层网络中和权值初始值太大的情况；梯度消失现象：网络不学习，即参数不更新，一般出现在深层网络和采用了不合适的激活函数。

从深层网络角度来讲：对于深层网络的参数更新，需要梯度的反向传播，使用链式求导法则，当某一部分对激活函数求导大于1时，当层数增多时，梯度更新将以指数级增加，发生梯度爆炸。如果该部分小于1，那么随着层数增多，求出的梯度更新将会以指数级减小，发生梯度消失。总结：从深层网络的角度来看，不同的层学习的速度差异很大，表现为网络中靠近输出的层学习的情况很好，靠近输入的层学习的很慢，有时候甚至训练了很久，前几层的权值和刚开始初始化的值差不多，因次，梯度消失和梯度爆炸的根本原因是反向传播的链式求导法则，属先天不足。

从激活函数角度来讲：激活函数的选择 如sigmoid。

[详解机器学习中的梯度消失、爆炸原因及其解决方法](https://blog.csdn.net/qq_25737169/article/details/78847691)

解决方法：

+ 预训练+微调
+ 梯度剪切、正则
+ 更换激活函数 ReLU LeakReLU等
+ batchnorm
  + BN就是通过一定的规范化手段，把每层神经网络输入的分布强行拉回到均值为0方差为1的标准正态分布，使得非线性函数的输入值落入到其比较敏感的区域，这样可以让梯度变大，避免梯度消失的问题，而且可以加快训练速度。
+ 残差结构

### 生成式模型和判别式模型有什么区别？各自的工作原理是什么？

监督学习方法分为生成方法(生成式模型)和判别方法(判别式模型)：

+ 生成式模型：由数据学习联合概率分布$P(X,Y)$，然后求出条件概率分布$P(Y|X)$作为预测模型，即$P(Y|X) = \frac{P(X,Y)}{P(X)}$，这样的方法之所以称为生成式模型，是因为模型表示了给定输入$X$产生输出$Y$的生成关系。典型的模型有：
  + 朴素贝叶斯
  + 隐马尔科夫模型(HMM)
  + 混合高斯模型
  + 贝叶斯网络
  + 马尔可夫随机场(MRF)
  + 深度信念网络(DBN)
+ 判别式模型：由数据直接学习决策函数$f(X)$或者条件概率分布$P(Y|X)$作为预测模型。判别式模型关心的是对给定的输入$X$，应该预测什么样的输出$Y$。典型的判别模型有：
  + K近邻(KNN)
  + 感知机
  + 决策树
  + 逻辑回归
  + 最大熵模型
  + 支持向量机
  + 提升方法
  + 条件随机场
  + 线性回归
  + 线性判别分析
+ 生成式模型的特点：生成式模型可以还原出联合概率分布$P(X,Y)$，而判别式模型则不能，生成式模型的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型，当存在隐变量时，仍可以用生成式模型学习，此时判别式模型就不能用了。优点：(1)实际上带的信息要比判别式模型丰富，研究单类问题比判别式模型灵活性强;(2)模型可以通过增量学习得到;(3)生成模型可以应付隐变量的情况，比如混合高斯模型就是含有隐变量的生成方法。缺点：(1)学习过程比较复杂;(2)实践中多数情况下判别模型效果更好。[参考文章](https://blog.csdn.net/Yaphat/article/details/52574748)

+ 判别式模型的特点：判别式模型直接学习的是条件概率$P(Y|X)$或决策函数$f(X)$，直接面对预测，往往学习的准确率更高，由于直接学习$P(Y|X)$或$f(X)$，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。优点：(1)分类边界更灵活，比使用纯概率方法或生成式模型得到的更高级;(2)准确率往往比生成式模型高;(3)不需要求解类别条件概率，所以允许我们对输入进行抽象(比如降维，定义特征等)，从而能够简化学习问题。缺点：(1)不能反映训练数据的本身特性。

### $L_1$正则和$L_2$正则如何理解？有什么区别？为什么能解决过拟合问题？

$L_1$正则化指权值向量中各个元素的绝对值之和，$L_2$正则化是指权值向量中各个元素的平方和再求平方根。$L_1$正则会产生稀疏解，$L_2$正则会产生比较小的解。以二维为例，$L_1$正则化项和误差项的交点常出现在坐标轴上，是个菱形，$w_1$或$w_2$为0，即权值向量中有零值元素，而$L_2$正则化项与误差项的交点常出现在某个象限中，是个圆，$w_1$和$w_2$均非0。

从贝叶斯的角度来看：正则化是假设模型参数服从先验概率，即为模型参数添加先验，只是不同的正则化方法的先验分布是不一样的，$L_1$正则是拉普拉斯先验，而$L_2$正则是高斯先验。这样就规定了参数分布，使得模型的复杂度降低，对噪声与异常点的抗干扰性的能力增强，从而提高了模型的泛化能力。[机器学习防止欠拟合、过拟合方法](https://zhuanlan.zhihu.com/p/29707029)

Lasso回归：逻辑回归的基础上加了$L_1$正则。
岭回归：逻辑回归的基础上加了$L_2$正则。

### 什么是过拟合,欠拟合，解决过拟合和欠拟合的方法有哪些？

过拟合(over-fitting)：过拟合是指学习时选择的模型所包含的参数过多，以致于出现这一模型图对已知数据预测的很好，但对未知数据预测很差的现象(—来自李航的统计机器学习)，原因总结就是数据太少以及模型太复杂。

过拟合原因：

+ 数据层面：(1)数据量太少；(2)训练集和测试集分布不均匀；(3)数据不纯，包含大量的噪声，模型过度拟合噪声数据。
+ 模型层面：模型太复杂

解决欠拟合的方法：

+ 添加其它项，有时候模型出现欠拟合是因为特征项不够导致的，可以添加其他特征项来解决
+ 添加多项式特征。将线性模型增加二次项或三次项使模型的拟合能力变强
+ 增加模型的复杂度
+ 减少正则化参数

解决过拟合现象的方法：

+ 数据集扩增：(从数据源头采集更多数据，复制原有数据并加上随机噪声，重采样，根据当前数据估计分布，用分布产生数据)
+ 特征选择
+ 正则化
+ 早停(Early Stopping)
+ dropout
  + **减少神经元之间复杂的共适应关系**： 因为dropout程序导致两个神经元不一定每次都在一个dropout网络中出现。（这样**权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况**）。 **迫使网络去学习更加鲁棒的特征** （这些特征在其它的神经元的随机子集中也存在）。换句话说假如我们的神经网络是在做出某种预测，它不应该对一些特定的线索片段太过敏感，即使丢失特定的线索，它也应该可以从众多其它线索中学习一些共同的模式（鲁棒性）。（这个角度看 dropout就有点像L1，L2正则，减少权重使得网络对丢失特定神经元连接的鲁棒性提高）
  + **蕴含模型集成的思想**。每次随机dropout一些神经元，相当于训练了多个不同的模型，最后在测试的时候是多个模型集成的结果。
+ 残差结构
+ 交叉验证

### 有哪些评价指标？AUC怎么求？AUC刻画的是什么？Precision和Accuracy的区别？

|      | Yes           | No           | 总计       |
| ---- | ------------- | ------------ | ---------- |
| Yes  | TP            | FN           | P(实为Yes) |
| No   | FP            | TN           | N(实为No)  |
| 总计 | P'(被分为Yes) | N'(被分为No) | P+N        |

评价指标

+ **正确率(accuracy)**:$accuracy = \frac{(TP+TN)}{P+N}$,正确率是被分对的样本数在所有样本数中的占比，通常来说，正确率越高，分类器越好。
+ **错误率(Error rate)**:错误率与正确率相反，描述被分类器错分的比例。
+ **灵敏度(sensitivity)**:$sensitivity=\frac{TP}{P}$,表示所有正例中被分对的比例，衡量了分类器对正类的识别能力。
+ **特异性(specificity)**:$specificity=\frac{TN}{N}$,表示所有负例中被分对的比例，衡量了分类器对负例的识别能力。
+ **精度(Precision)**:$precision=\frac{TP}{TP+FP}$,精度是精确性的度量，表示被分为正例的样本中实际为正例的比例。
+ **召回率(Recall)**:$recall=\frac{TP}{TP+FN}$,召回率是覆盖面的度量，度量多少个正例被分为正例，召回率和灵敏度一样。
+ **$F_1$score**:综合了查准率(精度)和查全率(召回率)，$F_1=\frac{2\times precision \times recall}{precision+recall}$.

AUC值是一个概率值，当你随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值。当然，AUC值越大，当前的分类算法越有可能将正样本排在负样本前面，即能够更好的分类。AUC越大，模型越可靠。


### 常见的损失函数

损失函数用来衡量算法运行时，估计模型的预测值和真实值的不一致程度，是一个非负实值函数，损失函数越小，模型的鲁棒性越好。损失函数分为经验风险损失函数和结构风险损失函数。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是在经验风险损失函数的基础上加了正则化项。<br>
+ 0-1损失函数
+ 绝对值损失函数
+ 平方损失函数
+ 对数损失函数
+ 指数损失函数
+ Hinge损失函数
+ 交叉熵损失函数
+ SmoothL1损失

### 常见的特征选择算法和特征提取算法

子集搜索+子集评价=特征选择算法
子集搜索：前向搜索、后向搜索、双向搜索
子集评价：信息增益

+ 特征选择算法
  + Filter方法(过滤式方法)
    + 过滤式选择先对数据集进行特征选择，然后在训练学习器，特征选择过程与后序学习器无关，代表算法 Relief(相关系数)，信息增益(ID3),卡方检验；
  + wrapper方法(包裹式方法)
    + 包裹式特征选择直接把最终将使用的学习器性能作为特征子集的评价准则，其直接针对给定的学习器进行优化，一般性能比过滤式方法要好，但是计算开销较大，代表算法 LVW；
  + Embedded方法(嵌入式方法)
    + 嵌入式特征选择是将特征选择过程与学习器训练过程融为一体，两者在同一个优化过程中完成，主要方法：正则化 $L_1$ Lasso回归(在线性回归的过程中加入了$L_1$正则项)。

+ 特征提取算法
  + PCA(主成分分析)
  + LDA(线性判别分析)
  + ICA(独立成分分析)

### 常见的分类算法(传统)有哪些？

线性分类器：

+ 线性回归
+ 逻辑回归
+ 支持向量机
+ 线性判别分析
+ 最大熵模型
+ 感知机

非线性分类器

+ 决策树
+ 贝叶斯分类
+ K近邻

## 14. 当数据特征非常多相关的时候，哪些模型会失效？

1.朴素贝叶斯分类器模型 2.SVM 3.LR 4.决策树  答案：1，3。

个人理解：

+ 朴素贝叶斯分类器：采用"属性条件独立假设"，对已知类别，假设所有属性相互独立。换言之，假设每个属性独立地对分类结果发生影响。
+ SVM：针对线性不可分的情况，可以利用核函数将其映射到高维空间线性可分。
+ LR：其实质上是一个线性分类器，处理不好特征之间相关的情况。
+ 决策树：擅长处理非线性的问题。

### 特征离散化？为什么要进行特征离散化？有哪些方法？

连续特征离散化的基本假设，是默认连续特征不同区间的取值对结果的贡献是不一样的。

**特征的连续值在不同的区间的重要性是不一样的，所以希望连续特征在不同的区间有不同的权重**，**实现的方法就是对特征进行划分区间，每个区间为一个新的特征**。常用做法，就是先对特征进行排序，然后再按照等频离散化为N个区间。

+ 离散特征的增加和减少都很容易，易于模型的快速迭代；
+ 逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合；
+ 特征离散化后，模型会更稳定。对于区间里面的特征具有鲁棒性；
+ 特征离散化以后，起到了简化逻辑回归模型的作用，降低了模型过拟合的风险。

离散化的方法：

### 样本不平衡问题？有哪些方法？

**样本不平衡**是指分类任务中不同类别的训练样本数量差别很大的情况。

常见的样本不平衡的解决方法：

+ **扩大数据集**：增加小类样本的数据。
+ **对大类样本数据欠采样**：可以利用集成学习的思想，将大类样本数据划分为若干个集合供不同的学习器使用，相当于对每个学习器都进行了欠采样，但全局不会丢失重要信息。
+ **对小类样本数据进行过采样**：可以对训练集进行插值来产生新的少类样本，对于图像的话，可以对图像进行一些操作来增大小样本数据，比如，翻转，颜色变化，平移，放大缩小等等。
+ **数据代价加权**：对小样本数据赋予较大的权值，降低大类样本的权值。
+ 转化问题思考角度：可以将小样本当作异常点，进行异常点检测。

## 数据结构和语言相关问题

### 1. C++中指针和引用的区别？分别在什么场景下使用？

引用是别名，指针时地址。指针在运行时可以改变所指向的值，而引用一旦与某个对象绑定后就不再改变。也就是说指针可以被重新赋值以指向另一个对象，但是引用则总是在初始化时被指定的对象，以后不能改变，但是指向的内容可以改变。

### 2. 数组和链表的区别和使用场景？

数组的内存区间是连续的，可以用下标进行访问，它的特点是查找快，以O(1)的时间查找，增加删除困难，适用于查找多的场景中。

链表的内存空间是非连续的，链表的每个结点都有指向下一个结点的指针，它的特征是插入，删除容易，查找困难，适用于插入和删除比较多的场景中。

### 3. 快速排序和堆排序

**快速排序**：采用分治的思想，关键函数partition，将数组中的元素分为两部分，一部分大于当前值，一部分小于当前值，然后分别递归处理这两部分。

**堆排序**：利用大顶堆或小顶堆进行排序的。它首先利用数组元素构建一个大顶堆，然后将堆顶元素和数组中最后一个元素交换，然后下沉上浮更新大顶堆，再将堆顶元素和数组中倒数第二个元素交换，重复上述步骤。

### 4. python中的一些知识

#### (1) lambda函数

lambda是匿名函数，它可以接收任意多参数，并返回单个表达式的值。**lambda表达式只允许包含一个表达式**，不能包含复杂的语句，**该表达式的运行结果就是函数的返回值**。

#### (2) 字典，列表是什么数据结构？

**字典**：它是一种容器，它里面的元素以键值对的形式存在，是无序的，其中键不可以重复，可以通过键来获取键对应的值。

**列表**：它也是一种容器，它里面的元素是有顺序的，可以通过索引对其中的元素进行访问。

#### (3) 怎么读取文件更加高效？

如果对于很大的文件，常常不采用`read()`和`readlines()`函数将所有内容读入内存，而是利用`for`循环逐行读取，利用了迭代器，所以它不会一次性将所有文件都载入内存。

#### (4) 迭代器和生成器

**迭代器**：迭代器（生成器）在Python中是一种很常用也很好用的数据结构，比起列表(list)来说，迭代器最大的优势就是延迟计算，按需使用，从而提高开发体验和运行效率。

**生成器**：生成器是一个特殊的程序，可以被用作控制循环的迭代行为，python中生成器是迭代器的一种，使用yield返回值函数，每次调用yield会暂停，而可以使用next()函数和send()函数恢复生成器。生成器类似于返回值为数组的一个函数，这个函数可以接受参数，可以被调用，但是，不同于一般的函数会一次性返回包括了所有数值的数组，**生成器一次只能产生一个值，这样消耗的内存数量将大大减小**，而且允许调用函数可以很快的处理前几个返回值，因此生成器看起来像是一个函数，但是表现得却像是迭代器


6. 假设有一坨数据，其中有一个特征是pv，有的样本该特征值可以达到几百万，有的则接近于零，这个该如何归一化？
答：用每个值除以总体最大值和最小值的差
7. 这样做会有什么问题？
8. 那有什么解决方法吗？

13.介绍一下随机梯度下降算法，它的随机性提现在哪里？
16.介绍了一下天猫海外的业务，扯到那道编程题，说一下解决思路
17.一个小时编程完成：
长标题变短标题
1，实现一个函数，输入长字符串（大于30个字符），输出短字符串（小于等于10个字符）
2，提供2个词典，一个为同义词词典，key为w，value为w的同义词；一个为词语重要度词典，key为w，value为w的重要度
3，需要基于重要度词典，实现简单的分词；可以网上搜索基于词典的分词代码
4，输出标题中的词语尽量保持原来的顺序