# 机器学习问题总结

## 无监督学习算法

### K-means原理，如何选择K，手写K-means

**原理**：K-means是一种迭代求解的聚类分析算法，其步骤是，首先随机选取k个聚类中心，然后计算每个样本距各个聚类中心的距离，把样本划分到距离它最近的聚类中心，更新聚类中心，如果聚类中心不再改变或者聚类中心的变化在误差范围内，则停止，否则重复上面步骤。K-means算法简单，好理解，运行速度快。

**k的选取(手肘法)**：当类别数未知的情况下，我们可以假设类别数是逐步增加的，然后画出准则函数随着类别k的变化曲线，刚开始，准则我函数会随着k的增大而迅速减小，当k再增加时，准则函数的下降不在那么明显，我们通常会选取拐点处的k值作为适合的聚类类别数。

```
伪代码
1. 创建k个点作为起始质心(通常随机选择)
2. 对每个样本分别计算到K个质心的相似度或距离，将该样本划分到相似度最高或距离最短的质心所在类
3. 对该轮聚类结果，计算每一个类别的质心，新的质心作为下一轮的质心
4. 判断算法是否满足终止条件，满足终止条件结束，否则继续第2、3、4步。
```

**手写K-means**：

```python
import math
import matplotlib.pyplot as plt
import random

def getEuclidean(point1, point2):
    dimension = len(point1)
    dist = 0.0
    for i in range(dimension):
        dist += (point1[i] - point2[i]) ** 2
    return math.sqrt(dist)

def k_means(dataset, k, iteration):
    #初始化簇心向量
    index = random.sample(list(range(len(dataset))), k)
    vectors = []
    for i in index:
        vectors.append(dataset[i])
    #初始化标签
    labels = []
    for i in range(len(dataset)):
        labels.append(-1)
    #根据迭代次数重复k-means聚类过程
    while(iteration > 0):
        #初始化簇
        C = []
        for i in range(k):
            C.append([])
        for labelIndex, item in enumerate(dataset):
            classIndex = -1
            minDist = 1e6
            for i, point in enumerate(vectors):
                dist = getEuclidean(item, point)
                if(dist < minDist):
                    classIndex = i
                    minDist = dist
            C[classIndex].append(item)
            labels[labelIndex] = classIndex
        for i, cluster in enumerate(C):
            clusterHeart = []
            dimension = len(dataset[0])
            for j in range(dimension):
                clusterHeart.append(0)
            for item in cluster:
                for j, coordinate in enumerate(item):
                    clusterHeart[j] += coordinate / len(cluster)
            vectors[i] = clusterHeart
        iteration -= 1
    return C, labels
```

## 补充

### LR为什么使用sigmoid函数作为激活函数

[解释logistic回归为什么要使用sigmoid函数](https://blog.csdn.net/qq_19645269/article/details/79551576)

### SVM为什么不适合处理大数据？

SVM的空间消耗主要是在存储训练样本和核矩阵，由于SVM是借助二次规划来求解支持向量，而求解二次规划将涉及m阶矩阵的计算（m为样本的个数），**当m数目很大时该矩阵的存储和计算将耗费大量的内存和运算时间。如果数据量很大，SVM的训练时间就会比较长**，所以SVM在大数据的使用中比较受限。

### 为什么LR适合大样本，SVM适合小样本？

SVM不适合大样本，因为计算的原因，SVM会非常慢。SVM适合小样本是因为SVM只由支持向量决定，所以样本多少对最终的支持向量影响不大。LR适合大样本是因为我们可以用在线数值方法进行迭代求解，比如随机梯度下降，这样速度很快也非常适合并行计算。但是LR也同样适合小样本，只要满足样本数量是变量数量的10倍以上就够了。
[为什么说LR适合大样本，SVM适合小样本？](http://sofasofa.io/forum_main_post.php?postid=1004333)

### SVM中样本不平衡的处理方法

除了通用的样本不平衡处理方法外，在SVM中我们可以通过为正负类样本设置不同的惩罚因子来解决样本偏斜的问题。具体做法是为负类设置大一点的惩罚因子，因为负类本来就少，不能再分错了，然后正负类的惩罚因子遵循一定的比例，比如正负类数量比为100：1，则惩罚因子的比例直接就定为1:100，具体值要通过实验确定。

### 数据不标准化对SVM的影响

大特征值会掩盖小特征值(内积计算)。高斯核会计算向量间的距离，也会产生同样的问题；多项式核会引起数值问题，影响求解速度。数据标准化后会丢失一些信息，预测的时候也要进行标准化。

### 样本不平衡时，如何评价分类器的好坏？

使用ROC曲线，ROC曲线下的面积(AUC)，介于0.1和1之间，是一个概率值，当你随机挑选一个正样本以及负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值，AUC值越大，当前分类算法越有可能将正样本排在负样本前面。Auc作为数值可以直观的评价分类器的好坏，值越大越好，随机情况大概是0.5，所以一般不错的分类器AUC至少要大于0.5。选择ROC和ROC下曲线面积是因为分类问题经常会碰到正负样本不均衡的问题，此时准确率和召回率不能有效评价分类器的性能，而ROC曲线有个很好的特性：**当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变**。

### 决策树模型在特征选择时候的准则

#### 信息增益

熵：是表示随机变量不确定性的度量。随机变量X的熵定义为(熵只依赖于X的分布，与X的取值无关，可以写成$H(p)$)：

$$
H(p) = -\sum_i^np_ilogp_i
$$

条件熵：$H(D|A)$表示在已知随机变量X的条件下，随机变量Y的不确定性。
**信息增益：集合D的经验熵$H(D)$与特征A给定条件下D的经验条件熵$H(D|A)$之差**，即

$$
g(D,A) = H(D)-H(D|A)
$$

#### 增益率(信息增益比)

特征A对训练数据集D的信息增益比$g_R(D,A)$定义为其信息增益$g(D,A)$与训练数据集D的经验熵$H(D)$之比：

$$
g_R(D,A) = \frac{g(D,A)}{H(D)}
$$

#### 基尼指数

分类问题中，假设有K个类，样本点属于第K类的概率为$p_k$，则概率分布的基尼指数定义为：

$$
Gini(p) = \sum_{k=1}^Kp_k(1-p_k) = 1-\sum_{k=1}^Kp_k^2
$$

对于给定的样本集合D，其基尼指数为：

$$
Gini(D) = 1 - \sum_{k=1}^K(\frac{|C_k|}{|D|})^2
$$

如果样本集合D根据特征A是否取某一可能的值a被分割成$D_1$和$D_2$两部分，则在特征A的条件下，集合D的基尼指数定义为：

$$
Gini(D,A) = \frac{|D_1|}{|D|}Gini(D_1) + \frac{|D_2|}{|D|}Gini(D_2)\\
Gini(D,A) = \sum_{v=1}^V\frac{|D_v|}{|D|}Gini(D_v) v是当a是不同取值的集合。
$$

基尼指数$Gini(D)$表示集合D的不确定性，基尼指数$Gini(D,A)$表示经$A=a$分割后集合D的不确定性。基尼指数越大，样本集合的不确定性也越大。

### GBDT为什么将损失函数的负梯度在当前模型的值作为残差的近似？

一种说法：为了可以扩展到更复杂的损失函数中。

**推导：**

GBDT的求解过程就是梯度下降在**函数空间**的优化过程。

通过一阶泰勒展开证明负梯度方向是下降最快的方向，对于函数f：

$$
f(\theta_{k+1})\approx f(\theta_k) + \frac{\partial f(\theta_k)}{\partial \theta_k}(\theta_{k+1 - \theta_k})
$$

则优化函数时：$\theta_{k+1} = \theta_k - \eta \frac{\partial f(\theta_k)}{\partial \theta_k}$
GBDT对损失函数一阶泰勒展开：

$$
L(y,F_m(x)) \approx L(y, F_{m-1}(x)) + \frac{\partial L(y, F_{m-1}(x))}{\partial F_{m-1}(x)}(F_m(x)-F_{m-1}(x))\\
即：L(y,F_m(x)) \approx L(y, F_{m-1}(x)) + \frac{\partial L(y, F_{m-1}(x))}{\partial F_{m-1}(x)}T_m(x)
$$

则优化$L(y, F(x))$的时候：

$$
F_m(x) = F_{m-1}(x) - \eta \frac{\partial L(y, F_{m-1}(x))}{\partial F_{m-1}(x)}\\
即：T_m(x) = -\eta \frac{\partial L(y, F_{m-1}(x))}{\partial F_{m-1}(x)}
$$

所以需要当前学习器来学习负梯度，只是相差了一个$\eta$。所以说，无论损失函数是什么形式，每个决策树拟合的都是负梯度。准确的说，不是用负梯度代替残差，而是当损失函数是均方损失时，负梯度刚好是残差，残差只是特例。
[参考资料：GBDT为什么拟合上一次的负梯度](https://blog.csdn.net/youhuakongzhi/article/details/94488888)

### XGBoost在GBDT的基础上做了哪些改进？

1. XGBoost在目标函数中加入了正则项，因为GBDT中的正则化主要依靠一些工程措施，局限性与可操作性较差。XGBoost直接将正则化加入到目标函数中，在每一轮的迭代均在数学层面进行了正则化，效果与可操作性大大提升。
2. XGBoost的优化准则完全基于目标函数的最小化推导，并采用了二阶泰勒展开，使得自定义损失函数成为可能。
3. shrinkage技术：在每次迭代中对基分类器的输出再乘上一个缩减权重。该操作是为了减少每个基分类器的影响力，留更多的空间给后面的基分类器来提升，相信集体决策。
4. 采样技术：无放回抽样，具体含义是每轮训练随机使用部分训练样本，其实这里是借鉴了随机森林的思想。包括行采样和列采样。行采样就是每次只抽取部分样本进行训练；列采样分两种，一种是在生成基分类器之前就随机选好特征，一种是在每一层中随机选择参与训练的特征。

### 为什么XGBoost要用泰勒展开(二阶泰勒展开)，优势是什么？

XGBoost使用了一阶和二阶偏导, 二阶导数有利于梯度下降的更快更准. 使用泰勒展开取得函数做自变量的二阶导数形式, 可以在不选定损失函数具体形式的情况下, 仅仅依靠输入数据的值就可以进行叶子分裂优化计算, 本质上也就把损失函数的选取和模型算法优化/参数选择分开了. 这种去耦合增加了XGBoost的适用性, 使得它按需选取损失函数, 可以用于分类, 也可以用于回归。

### XGBoost和lightGBM的区别



### 交叉验证是如何做的？K折交叉验证中的k是如何选取的？

将数据集均等划分为K组，选取其中的一组用于测试，其余的k-1组都用于训练，然后依次更换用于测试的一组，这样就可以得到k组训练/测试集，然后进行k次训练和测试，最终的测试结果是这k个测试结果的均值。
k的选取是一个偏差和方差权衡的过程，k越大，每次投入的训练集的数据越多，模型的偏差越小，但是k远大，又意味着每一次训练选取的训练集之间的相关性越大，而这种大相关性会导致大有的方差。一般来说，我们可以选择k为5或10，如果数据量很少的时候，可以采用留一法。

## EM算法

概率模型有时候既含有观测变量，又含有隐变量或潜在变量。如果概率模型的变量都是观测变量，那么给定数据，可以直接用极大似然估计或者贝叶斯估计的方法来估计模型参数，但是当模型含有隐变量时，就不能简单的使用这些估计方法，通常采用EM算法来求解含有隐变量的概率模型参数。

EM算法使用两个步骤交替计算即：

1. 期望E步：利用当前估计的参数值来计算对数似然的期望值；
2. 最大化M步：寻找能使E步产生的似然期望最大化的参数；
3. 然后，新得到的参数值重新被用于E步，直至收敛到局部最优解。

缺点：传统的EM算法对初始值敏感，聚类结果随不同的初始值而波动较大。总的来说，EM算法收敛的优劣很大程度上取决于其初始参数。

[EM算法原理](https://www.cnblogs.com/coshaho/p/9573367.html)

## 评价指标补充

### ROC曲线

ROC全称是“受试者工作特征”(Receiver OperatingCharacteristic)曲线。我们根据学习器的预测结果，把阈值从0变到最大，即刚开始是把每个样本作为正例进行预测，随着阈值的增大，学习器预测正样例数越来越少，直到最后没有一个样本是正样例。在这一过程中，每次计算出两个重要量的值，分别以它们为横、纵坐标作图，就得到了“ROC曲线”。ROC曲线的纵轴是“真正例率”(True Positive Rate, 简称TPR)，横轴是“假正例率”(False Positive Rate,简称FPR)。对角线对应于“随机猜测”模型，而点(0,1)则对应于将所有正例预测为真正例、所有反例预测为真反例的“理想模型”。

$$
TPR = \frac{TP}{TP+FN}\\
FPR = \frac{FP}{FP+TN}
$$

[ROC曲线和AUC面积理解](https://blog.csdn.net/program_developer/article/details/79946787)

### ROC曲线的含义

**主要作用**：

1. ROC曲线能很容易的查出任意阈值对学习器的泛化性能影响。
2. 有助于选择最佳的阈值。ROC曲线越靠近左上角，模型的查全率就越高。最靠近左上角的ROC曲线上的点是分类错误最少的最好阈值，其假正例和假反例总数最少。
3. 可以对不同的学习器比较性能。将各个学习器的ROC曲线绘制到同一坐标中，直观地鉴别优劣，靠近左上角的ROC曲所代表的学习器准确性最高。

**优点**：

1. 该方法简单、直观、通过图示可观察分析方法的准确性，并可用肉眼作出判断。ROC曲线将真正例率和假正例率以图示方法结合在一起，可准确反映某种学习器真正例率和假正例率的关系，是检测准确性的综合代表。
2. 在生物信息学上的优点：ROC曲线不固定阈值，允许中间状态的存在，利于使用者结合专业知识，权衡漏诊与误诊的影响，选择一个更加的阈值作为诊断参考值。


### 什么是AUC？AUC面积的意义？

AUC就是ROC曲线下的面积，衡量学习器优劣的一种性能指标。从定义可知，AUC可通过对ROC曲线下各部分的面积求和而得。
**AUC是衡量二分类模型优劣的一种评价指标，表示预测的正例排在负例前面的概率**。AUC就是从所有正样本中随机选择一个样本，从所有负样本中随机选择一个样本，然后根据你的学习器对两个随机样本进行预测，把正样本预测为正例的概率$p_1$，把负样本预测为正例的概率$p_2$，$p_1>p_2$的概率就等于AUC。所以AUC反映的是分类器对样本的排序能力。根据这个解释，如果我们完全随机的对样本分类，那么AUC应该接近0.5。

另外值得注意的是，AUC的计算方法同时考虑了学习器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器做出合理的评价。AUC对样本类别是否均衡并不敏感，这也是不均衡样本通常用AUC评价学习器性能的一个原因。

## 目标函数、损失函数、代价函数的区别？

1. 损失函数：计算的是一个样本的误差
2. 代价函数：是整个训练集上所有样本误差的平均
3. 目标函数：代价函数 + 正则化项

损失函数和代价函数是同一个东西，目标函数是一个与他们相关但更广的概念，对于目标函数来说在有约束条件下的最小化就是损失函数。